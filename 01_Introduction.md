# Introduction

## 동시성(Concurrency)

- 동시성은 여러 가지 일이 동시에 무작위 순서로 일어나는 것을 의미한다.
- Go는 동시성에 대한 지원을 기본적으로 제공한다.

## Why we need to think about concurrency?

```go
// Add - 숫자를 더하는 순차적인 코드
func Add(numbers []int) int64 {
	var sum int64
	for _, n := range numbers {
		sum += int64(n)
	}
	return sum
}
```

이 function을 더 빠르게 실행하는 방법이 없을까?

## Computing Environment

- 멀티코어 프로세서 (Add, idle, idle, idle)
- `Add()`는 싱글코어에서 실행된다. 나머지 코어들은 여전히 idle 상태이다.
- 다른 코어도 사용하여 계산을 더 빠르게 하고 싶다.
- 한 가지 방법은, 입력값을 나눠서 다른 코어에서 병렬적으로 각 파트에 `Add()` 함수의 여러 인스턴스를 실행할 수 있다.

```go
// AddConcurrent - 숫자를 더하는 동시성 코드
func AddConcurrent(numbers []int) int64 {
	// 시스템의 모든 코어 활용
	numOfCores := runtime.NumCPU()
	runtime.GOMAXPROCS(numOfCores)

	var sum int64
	max := len(numbers)

	sizeOfParts := max / numOfCores

	var wg sync.WaitGroup

	for i := 0; i < numOfCores; i++ {
		// Divide the input into parts
		start := i * sizeOfParts
		end := start + sizeOfParts
		part := numbers[start:end]

		// Run computation for each part in separate goroutine.
		wg.Add(1)
		go func(nums []int) {
			defer wg.Done()

			var partSum int64

			// Calculate sum for each part
			for _, n := range nums {
				partSum += int64(n)
			}

			// Add sum of each part to cumulative sum
			atomic.AddInt64(&sum, partSum)
		}(part)
	}
	wg.Wait()
	return sum
}
```

## 동시성(Concurrency) vs 병렬성(Parallelism)

- 동시성은 실행 중인 프로세스들을 결합하는 행위이다.
  - e.g. OS는 마우스, 키보드, 스크린 등 다양한 주변 장치를 제어하지만 이러한 여러 개의 장치를 관리하기 위해서 병렬 작업이 필요한 건 아니다. 하나의 CPU 코어로도 처리가 가능하다.
- 여러 개의 작업을 다루는 것에 관한 개념이다.
- 동시성을 통해 병렬성을 달성할 수 있긴 하지만 동시성의 목적이 병렬성은 아니다.
- 동시성의 목적은 구조화에 있다.
- 동시성은 프로그램을 여러 개의 작은 부분으로 나누어 각각의 부분이 서로 정보를 주고 받으며 독립적으로 실행될 수 있도록 하는 구조화 작업이다.
- 병렬성은 여러 작업을 동시에 실행할 수 있는 능력이다.
  - e.g. 두 개의 코어가 각기 다른 스레드/프로세스를 실행한다.

# Processes and Threads

## 운영체제(Operating System)

운영체제는 모든 프로세스가 CPU, 메모리 및 기타 리소스에 접근할 수 있는 공정한 기회를 준다. 대부분의 경우 모든 프로세스게 도일한 기회를 준다. 높은 우선순위의 작업이 우선순위를 가질 수도 있다.

동시성의 아이디어는 프로세스, 스레드에서 시작된다. 

## 프로세스(Process)란

프로세스란 실행 중인 프로그램의 인스턴스를 말한다. 프로세스는 프로그램이 실행할 수 있는 환경을 제공한다. 프로그램이 실행되면, 운영체제는 프로세스를 생성하고, 가상 주소 공간에 메모리를 할당한다. 

가상 주소 공간은 다음을 포함한다.

- 컴파일된 머신 코드인 `Code` 세그먼트
- 전역변수를 포함하는 `Data` 리전
- 동적 메모리 할당을 하는 `Heap` 세그먼트
- 함수의 지역 변수를 저장하는 `Stack`

## 스레드(Threads)란

스레드는 CPU가 허용하는 최소 실행 단위이다. 각 프로세스에는 적어도 하나의 스레드가 있다. 이를 메인 스레드라고 한다. 프로세스는 여러 개의 스레드를 가질 수 있다. 스레드는 동일한 주소 공간을 공유한다. 각 스레드에는 고유한 스택이 있다. 스레드는 서로 독립적으로 실행될 수 있다. 운영체제 스케줄러는 프로세스 수준이 아닌 스레드 수준에서 스케줄링 결정을 내린다. 스레드는 동시에 실행되거나 병렬적으로 실행될 수 있다.

## 스레드 상태(Thread States)

- 프로세스가 만들어지면 메인스레드가 Ready 대기열에 들어간다. 이를 Runnable 상태라고 한다.
- CPU를 사용할 수 있게 되면 스레드가 실행되기 시작하고 각 스레드에는 타임 슬라이스가 제공된다.
- 해당 타임 슬라이스가 만료되면 스레드가 선점되어 대기열에 다시 배치된다.
- 디스크 또는 네트워크 작업에서 읽기/쓰기 또는 다른 프로세스의 이벤트 대기와 같은 I/O 작업으로 인해 스레드가 블록되면 I/O 작업이 완료될 때까지 Waiting 대기열에 배치된다. 
- 완료되면, Ready 대기열에 다시 배치된다.

## 컨텍스트 전환(Context Switch)에 드는 비용은 크다

컨텍스트 전환에 드는 비용은 크다.

CPU는 현재 실행 중인 스레드의 컨텍스트를 메모리에 복사하고, 다음으로 선택된 스레드의 컨텍스트를 복원하는 데 시간을 소비해야 한다.

또한 컨텍스트 전환을 수행하려면 수천 개의 CPU 명령이 필요하다. CPU가 애플리케이션을 실행하는 대신 컨텍스트 전환을 수행하기 때문에 시간이 낭비된다.

동일한 프로세스의 스레드 간의 컨텍스트 전환이 다른 프로세스의 스레드 간의 컨텍스트 전환에 비해 상대적으로 비용이 적다.

그래서 프로세스 당 스레드 수를 스케일할 수 있을까? 사실 많이는 할 수 없다.

- Process Context
  - 프로세스 상태
  - CPU 스케줄링 정보
  - 메모리 관리 정보
  - 어카운팅 정보
  - I/O 상태 정보
- Thread Context
  - 프로그램 카운터
  - CPU 레지스터
  - 스택

## 스레드의 한계: C10k 문제

프로세스에 너무 많은 스레드를 확장하면, C10k 문제가 일어난다.

스케줄러는 CPU 코어에서 실행할 각 프로세스의 타임 슬라이스를 할당한다. 이 타임 슬라이스는 스레드 간에 균등하게 분할된다. 

만약 스케줄러 주기를 10ms로 정의하고, 2개의 스레드가 있는 경우, 각 스레드는 실행을 위해 각각 5ms가 얻게 된다. 5개의 스레드가 있다면, 각 스레드는 실행하는 데 2ms를 얻는다. 그러나, 1000개의 스레드가 있다면 어떻게 될까? 각 스레드는 10 microseconds를 얻을 것이다. 매우 좋지 않다. CPU는 애플리케이션을 실행하는 시간보다 컨텍스트 전환에 더 많은 시간을 소비할 것이다.

의미있는 작업을 위해서 스레드에는 최소 2ms 이상이 필요하다. 스레드의 최소 시간이 2ms일 때, 스케줄러 주기에 1000개의 스레드를 실행하려면 스케줄러 주기는 2초가 된다. 10000개의 스레드를 실행하려면 스케줄러 주기는 20초가 된다. 실행의 한 사이클을 완료하려면 20초가 걸린다. 각 스레드는 다음 실행을 위해 20초를 기다려야 한다. 따라서 애플리케이션은 반응이 느려질 것이다.

## 스레드의 한계: 고정된 스택 크기
또 다른 이슈는 스택 크기이다. 운영체제는 각 스레드에 고정된 스택 크기를 제공한다. 실제 크기는 하드웨어마다 다르다. 예를 들어, 내 머신은 스택 크기가 8MB이다. 8GB의 메모리가 있으므로, 이론적으로 1000개의 스레드를 생성할 수 있다. 따라서 고정된 스택 크기는 가지고 있는 메모리 양에 생성할 수 있는 스레드 수를 제한하게 된다.

# Why Concurrency is hard

## Shared Memory

- 스레드는 메모리를 공유하면서 서로 커뮤니케이션한다.
- 스레드는 프로세스의 heap, data 영역을 공유한다.
- 그러나 이러한 메모리 공유는 스레드를 동시에 실행하는 데 많은 복잡성을 유발한다.
- 따라서 두 개의 스레드가 동시에 실행되고 있고 하나의 스레드가 메모리에 쓰기를 시도하면서 동일한 영역의 메모리에 액세스하려고 하면 데이터 경쟁이 발생하고 프로그램의 결과는 결정적이지 않게 된다.

## Concurrent Access and Atomicity

- i++
- 두 스레드가 경쟁하는 상황
- 스레드1이 저장하기 전에 스레드2가 선점하는 경우
    - 스레드1 Retrieve(0) Increment(1)
    - 스레드2 Retrieve(0) Increment(1) Store(1)
    - 스레드1 Store(1)
- 위 경우 최종 결과가 2가 되어야 하는데 1이 저장된다.
- 메모리에 동시 접근하는 것은 결정적이지 않은 결과를 끌어낼 수 있다.

## Memory Access Synchronization

- 스레드가 한 번에 독점적인 액세스 권한을 갖도록 공유 메모리에 대한 액세스를 보호해야 한다. i의 값을 증가시키기 위해 스레드1과 스레드2를 순차적으로 실행하도록 강제해야 한다.
- 증가 연산에 lock을 설정하는 방법으로 작업을 수행할 수 있다.
- 공유 메모리에 lock을 설정하는 것은 개발자의 관례이다. 개발자가 공유 메모리에 액세스하려고 할 때마다 lock을 얻어야 한다. 완료되면 lock을 해제해야 한다.

```
Thread1
-------
Lock()
    i++
Unlock()
```
```
Thread2
-------
Lock()
    i++
Unlock()
```

- 개발자가 이 규칙을 따르지 않으면 독점적 접근을 보장하지 않으며, 언젠가 경주 조건에 도달한다.
- lock은 병렬성을 감소시키는 문제가 있다. lock이 스레드를 순차적으로 실행하도록 강제하기 때문이다.
- 따라서 공유 메모리에 액세스하는 critical section은 스레드 간의 보틀넥이 된다.
- lock의 부적절한 사용은 데드락을 유발한다.
    ```
    Thread1
    v1.Lock() // 1
        v2.Lock() // 3 WAITING
        ...
    ```

    ```
    Thread2
    v2.Lock() // 2
        v1.Lock() // 4 WAITING
        ...
    ```
- Circular wait은 데드락을 유발한다.

## Summary

- 스레드 간 메모리를 공유하는 것을 복잡성을 유발한다.
- 공유 메모리에 동시 접근하면 경주 조건이 발생하고 비결정적인 결과를 유발한다.
- 메모리 접근 동기화는 병렬성을 저하시켜서 한계가 생긴다.